---
# defaults file for admin
# Grafana Agent Configuration
grafana_agent:
  version: "0.43.4"
  install_dir: "/usr/local/bin"
  config_dir: "/etc/grafana-agent"
  data_dir: "/var/lib/grafana-agent"
  user: "grafana-agent"
  group: "grafana-agent"
  metrics_write:
    url: "http://prometheus:9090/api/v1/write"
  logs_write:
    url: "http://localhost:3100/loki/api/v1/push"
  extra_scrape_configs:
    - job_name: "polkadot"
      static_configs:
        - targets: ["localhost:9615"]
      metrics_path: "/metrics"
      scrape_interval: "15s"
  apparmor:
    enabled: "{{ apparmor.enabled and apparmor.profiles.grafana_agent.enabled }}"
    enforce: "{{ apparmor.profiles.grafana_agent.enforce }}"

# Node Exporter Configuration
node_exporter:
  enabled: true  # Optional installation
  version: "1.8.2"
  user: "node-exporter"
  group: "node-exporter"
  install_dir: "/usr/local/bin"
  port: 9100
  options:
    - "--collector.systemd"
    - "--collector.processes"
    - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|run)($|/)"
    - "--web.listen-address=:9100"
    - "--web.max-requests=20"
  apparmor:
    enabled: "{{ apparmor.enabled and apparmor.profiles.node_exporter.enabled }}"
    enforce: "{{ apparmor.profiles.node_exporter.enforce }}"

# Promtail Configuration
promtail:
  enabled: false  # Optional installation
  version: "3.2.1"
  user: "promtail"
  group: "promtail"
  port: 9080
  install_dir: "/usr/local/bin"
  config_dir: "/etc/promtail"
  data_dir: "/var/lib/promtail"
  positions_dir: "/var/lib/promtail/positions"
  loki_url: "http://localhost:3100/loki/api/v1/push"
  scrape_configs:
    - job_name: polkadot
      static_configs:
        - targets:
            - localhost
          labels:
            job: polkadot
            host: "{{ inventory_hostname }}"
            __path__: /var/log/polkadot/*.log
    - job_name: system
      static_configs:
        - targets:
            - localhost
          labels:
            job: system
            host: "{{ inventory_hostname }}"
            __path__: 
              - /var/log/syslog
              - /var/log/auth.log
  apparmor:
    enabled: "{{ apparmor.enabled and apparmor.profiles.promtail.enabled }}"
    enforce: "{{ apparmor.profiles.promtail.enforce }}"

# Monit Configuration
monit:
  enabled: true
  apparmor:
    enabled: "{{ apparmor.enabled and apparmor.profiles.monit.enabled }}"
    enforce: "{{ apparmor.profiles.monit.enforce }}"

# Teleport Configuration
teleport:
  enabled: true
  version: "13.3.2"
  user: "teleport"
  group: "teleport"
  install_dir: "/usr/local/bin"
  config_dir: "/etc/teleport"
  data_dir: "/var/lib/teleport"
  auth_token: ""  # Required for joining existing cluster
  auth_server: ""  # Required - Auth server address
  node_name: "{{ inventory_hostname }}"
  labels:
    role: "validator"
    environment: "production"
  auth:
    enabled: false  # Set to true if this is an auth server
  proxy:
    enabled: false  # Set to true if this is a proxy server
  ssh_service:
    enabled: true
    listen_addr: "0.0.0.0:3022"
  app_service:
    enabled: false
  kubernetes_service:
    enabled: false
  apparmor:
    enabled: "{{ apparmor.enabled and apparmor.profiles.teleport.enabled }}"
    enforce: "{{ apparmor.profiles.teleport.enforce }}"

# Firewall Configuration
firewall:
  type: "{{ 'ufw' if ansible_os_family == 'Debian' else 'firewalld' if ansible_os_family == 'RedHat' else 'none' }}"
  enabled: true
  default_incoming_policy: deny
  default_outgoing_policy: allow
  rules:
    - port: 22
      proto: tcp
      rule: allow
    - port: 3022
      proto: tcp
      rule: allow
    - port: 9100
      proto: tcp
      rule: allow
    - port: 9080
      proto: tcp
      rule: allow
    - port: 2812
      proto: tcp
      rule: allow

# UFW-specific configuration (Debian-based systems)
ufw:
  enabled: "{{ firewall.enabled and firewall.type == 'ufw' }}"
  default_incoming_policy: "{{ firewall.default_incoming_policy }}"
  default_outgoing_policy: "{{ firewall.default_outgoing_policy }}"
  rules: "{{ firewall.rules }}"

# FirewallD-specific configuration (RedHat-based systems)
firewalld:
  enabled: "{{ firewall.enabled and firewall.type == 'firewalld' }}"
  default_zone: public
  rules: "{{ firewall.rules }}"

# AppArmor Configuration
apparmor:
  enabled: true
  active: false  # Master switch for AppArmor
  profiles:
    grafana_agent:
      enabled: true
      enforce: true
    node_exporter:
      enabled: true
      enforce: true
    promtail:
      enabled: true
      enforce: true
    monit:
      enabled: true
      enforce: true
    teleport:
      enabled: true
      enforce: true
    fail2ban:
      enabled: true
      enforce: true

# Hardening Configurations
hardening:
  shared_memory:
    enabled: true
    mount_options: 
      - noexec
      - nosuid
      - nodev
  
  fail2ban:
    enabled: false
    ssh:
      max_retry: 3
      ban_time: 3600  # 1 hour
      find_time: 600  # 10 minutes
    services:
      - name: sshd
        enabled: true
      - name: ssh
        enabled: true
    apparmor:
      enabled: "{{ apparmor.enabled and apparmor.profiles.fail2ban.enabled }}"
      enforce: "{{ apparmor.profiles.fail2ban.enforce }}"

# Resource Monitoring Configuration
monitoring:
  enabled: true
  # Resource thresholds for alerts
  thresholds:
    cpu_usage: 80  # percentage
    memory_usage: 90  # percentage
    disk_usage: 85  # percentage
    disk_iops: 5000  # operations per second
    network_bandwidth: 100  # MB/s
  # Collection intervals
  intervals:
    resource_check: 60  # seconds
    metric_retention: 30  # days
  # Alert configuration
  alerts:
    cpu_sustained: 300  # seconds above threshold
    memory_sustained: 300  # seconds above threshold
    disk_sustained: 600  # seconds above threshold
  # Alert channels
  notification:
    slack:
      enabled: false
      webhook_url: ""  # Set via vault
    email:
      enabled: false
      recipients: []  # Set via vault

# OpsGenie Heartbeat Configuration
opsgenie:
  heartbeats:
    enabled: false
    api_key: ""  # Set this in your inventory or extra vars
    heartbeats:
      - name: node_health
        interval: 5  # minutes
        enabled: true
      - name: validator_status
        interval: 5  # minutes
        enabled: true
      - name: system_metrics
        interval: 10  # minutes
        enabled: true

# Binary Signatures
signatures:
  teleport:
    key_url: "https://deb.releases.teleport.dev/teleport-pubkey.asc"
    key_id: "14F9 5DA9 DE82 1DFF F4B8 0B61 D0E8 5A5E 8ED5 CDAA"